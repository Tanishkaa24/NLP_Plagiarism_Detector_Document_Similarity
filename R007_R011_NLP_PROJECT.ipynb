{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Title: Plagiarism Detector and Document Similarity\n",
        "\n",
        "Class: MBATech AI\n",
        "\n",
        "Batch: 1\n",
        "\n",
        "Subject: NLP\n",
        "\n",
        "Team Members: R007 Bhagyashree Birje, R011 Tanishkaa Chaturvedi\n",
        "\n",
        "Faculty: Ami Munshi"
      ],
      "metadata": {
        "id": "LZbNuYEZ8P9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "\n",
        "text1 = read_text_file('/content/text1.txt')\n",
        "text2 = read_text_file('/content/text4.txt')\n"
      ],
      "metadata": {
        "id": "-Vwe-4oUNRFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "read_text_file\n",
        "# Load the spaCy language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(text, remove_html_tags=True):\n",
        "\n",
        "    if remove_html_tags:\n",
        "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
        "\n",
        "    tokens = [token for token in tokens if token not in nlp.Defaults.stop_words and token not in string.punctuation]\n",
        "\n",
        "    cleaned_text = \" \".join(tokens)\n",
        "\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "id": "Bp0KScRtN47J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preprocessed_text1 = preprocess_text(text1)\n",
        "preprocessed_text2 = preprocess_text(text2)\n"
      ],
      "metadata": {
        "id": "QQyTuf7aORGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens1 = preprocessed_text1.split()\n",
        "tokens2 = preprocessed_text2.split()\n",
        "\n",
        "print(\"Tokens in Preprocessed Text 1:\")\n",
        "print(tokens1)\n",
        "\n",
        "print(\"\\nTokens in Preprocessed Text 2:\")\n",
        "print(tokens2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FfOUUV9OXJ_",
        "outputId": "d8f51ede-ff4a-4609-bc25-f123069befbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens in Preprocessed Text 1:\n",
            "['plagiarism', 'academic', 'offense', 'result', 'severe', 'consequence', 'student', 'crucial', 'student', 'understand', 'constitute', 'plagiarism', 'avoid', 'plagiarism', 'occur', 'person', 'use', 'idea', 'word', 'work', 'proper', 'attribution', 'avoid', 'plagiarism', 'credit', 'original', 'source', 'proper', 'citation', 'reference', 'academic', 'integrity', 'essential', 'student', 'strive', 'produce', 'original', 'work', 'maintain', 'credibility']\n",
            "\n",
            "Tokens in Preprocessed Text 2:\n",
            "['\\ufeffi', 'look', 'forward', 'spend', 'day', 'school', 'I', 'happy', 'school', 'meet', 'friend', 'interact', 'teacher', 'learn', 'new', 'thing', 'school', 'like', 'place', 'friend', 'family', 'surround', 'I', 'like', 'family', 'provide', 'I', 'education', 'necessary', 'skill', 'school', 'like', 'home', 'away', 'home', 'I', 'feel', 'place', 'homesick', 'place', 'I', 'learn', 'laugh', 'smile', 'play', 'enjoy', 'stir', 'emotion', 'I', 'good', 'reason', 'I', 'thankful', 'school', 'wonderful', 'teacher']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text, remove_html_tags=True):\n",
        "\n",
        "    if remove_html_tags:\n",
        "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
        "\n",
        "    tokens = [token for token in tokens if token not in nlp.Defaults.stop_words and token not in string.punctuation]\n",
        "\n",
        "    cleaned_text = \" \".join(tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "text1 = read_text_file('/content/text1.txt')\n",
        "text2 = read_text_file('/content/text4.txt')\n",
        "\n",
        "preprocessed_text1 = preprocess_text(text1)\n",
        "preprocessed_text2 = preprocess_text(text2)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf1 = vectorizer.fit_transform([preprocessed_text1])\n",
        "tfidf2 = vectorizer.transform([preprocessed_text2])\n",
        "\n",
        "cosine_sim = cosine_similarity(tfidf1, tfidf2)\n",
        "\n",
        "print(f\"The cosine similarity between the two documents is: {cosine_sim[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8xnG55K5tHF",
        "outputId": "4930cbfe-88ca-47c2-97ea-f37794c90d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cosine similarity between the two documents is: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text, remove_html_tags=True):\n",
        "\n",
        "    if remove_html_tags:\n",
        "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
        "\n",
        "    tokens = [token for token in tokens if token not in nlp.Defaults.stop_words and token not in string.punctuation]\n",
        "\n",
        "    cleaned_text = \" \".join(tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "text1 = read_text_file('/content/text1.txt')\n",
        "text2 = read_text_file('/content/text4.txt')\n",
        "\n",
        "preprocessed_text1 = preprocess_text(text1)\n",
        "preprocessed_text2 = preprocess_text(text2)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf1 = vectorizer.fit_transform([preprocessed_text1])\n",
        "tfidf2 = vectorizer.transform([preprocessed_text2])\n",
        "\n",
        "dense_tfidf1 = tfidf1.toarray()\n",
        "dense_tfidf2 = tfidf2.toarray()\n",
        "\n",
        "jaccard_sim = 1 - pairwise_distances(dense_tfidf1, dense_tfidf2, metric='jaccard')\n",
        "\n",
        "print(f\"The Jaccard similarity between the two documents is: {jaccard_sim[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR0sg8GVYHqC",
        "outputId": "89461809-102c-453a-b02e-3653b0883a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Jaccard similarity between the two documents is: 0.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
            "  if reduce_func is not None:\n"
          ]
        }
      ]
    }
  ]
}